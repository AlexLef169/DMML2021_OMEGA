{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lefebvre_DiFazioProject_guidelines_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexLef169/DMML2021_OMEGA/blob/main/Lefebvre_DiFazioProject_guidelines_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZKqCFFbNZ04"
      },
      "source": [
        "# Data Mining and Machine Learning - Project\n",
        "\n",
        "## Detecting Difficulty Level of French Texts\n",
        "\n",
        "### Step by step guidelines\n",
        "\n",
        "The following are a set of step by step guidelines to help you get started with your project for the Data Mining and Machine Learning class. \n",
        "\n",
        "#### 1. üìÇ Create a public GitHub repository for your team using this naming convention `DMML2021_[your_team_name]` with the following structure:\n",
        "- data (subfolder) \n",
        "- code (subfolder) \n",
        "- documentation (subfolder)\n",
        "- a readme file (.md): *mention team name, participants, brief description of the project, approach and summary of results table.*\n",
        "\n",
        "All team members should contribute to the GitHub repository.\n",
        "\n",
        "#### 2. üá∞ Join the competititon on Kaggle using an invitation link like this one: https://www.kaggle.com/t/69884669004b482c96dd59e5d0c52044 \n",
        "\n",
        "Under the Team tab, save your team name (`UNIL_your_team_name`) and make sure your team members join in as well. You can merge your user account with your teammates in order to create a team.\n",
        "\n",
        "#### 3. üìì Read the data into your colab notebook. There should be one code notebook per team, but all team members can participate and contribute code. \n",
        "\n",
        "You can use either direct the Kaggle API and your Kaggle credentials (as explained below and **entirely optional**), or dowload the data form Kaggle and upload it onto your team's GitHub repository under the data subfolder.\n",
        "\n",
        "#### 4. üíé Train your models and upload the code under your team's GitHub repo. Set the `random_state=0`.\n",
        "- baseline\n",
        "- logistic regression with TFidf vectoriser (simple, no data cleaning)\n",
        "- KNN & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Decision Tree classifier & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Random Forests classifier (simple, no data cleaning)\n",
        "- another technique or combination of techniques of your choice\n",
        "\n",
        "#### 5. üé• Create a YouTube video (10-15 minutes) of your solution and embed it in your notebook. Explain the algorithms used and the evaluation of your solutions. All projects will also be presented live by the group during the last class.\n",
        "\n",
        "DONE\n",
        "\n",
        "### Submission details (one per team)\n",
        "1. Add the link to your team's GitHub repository here: https://moodle.unil.ch/mod/url/view.php?id=841193\n",
        "\n",
        "2. Download a ZIPped file of your team's repositiory and submit it in Moodle here: https://moodle.unil.ch/mod/assign/view.php?id=1194395\n",
        "\n",
        "3. Post a link to your video in Slack under the project channel.\n",
        "\n",
        "### Grading (one per team)\n",
        "- 5 points presentation\n",
        "- 5 points video \n",
        "- 10 points notebook quality \n",
        "- 10 points your solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-14CAdOoinM"
      },
      "source": [
        "## Some further details for points 3 and 4 above.\n",
        "\n",
        "### 3. Read data into your notebook with the Kaggle API (entirely optional). \n",
        "\n",
        "You can also download the data from Kaggle and put it in your team's repo the data folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ_hnJzSNO2g",
        "outputId": "72d43c06-445e-454e-f426-3f87de5650e0"
      },
      "source": [
        "# reading in the data via the Kaggle API: optional\n",
        "\n",
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJPTz3D7TeQv",
        "outputId": "82b82ea0-3fd5-41c2-a001-5fff5482bdda"
      },
      "source": [
        "# install Kaggle\n",
        "! pip install kaggle"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKG1TCddRYTB"
      },
      "source": [
        "Log into your Kaggle account, go to Account > API > Create new API token. You will obtain a kaggle.json file, which you save on your Google Drive directy in my drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgzLj451YDfV",
        "outputId": "69326dfd-8675-4f86-b84b-1e5e339a02b9"
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‚Äò/root/.kaggle‚Äô: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrsZLalrSI3u"
      },
      "source": [
        "#read in your Kaggle credentials from Google Drive\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDI60LXKTPzf",
        "outputId": "6dcf5479-f549-47aa-ecb4-bd7d435d1e46"
      },
      "source": [
        "# download the dataset from the competition page\n",
        "! kaggle competitions download -c detecting-the-difficulty-level-of-french-texts"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "training_data.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "unlabelled_test_data.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daqvj7feTx60"
      },
      "source": [
        "# read in your training data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/training_data.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VxRSnk5bhTp8",
        "outputId": "4633eb61-e2cb-462e-a728-f8bdf65bf7eb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-59ac6c55-5d83-4988-9be6-50e56fb01c4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les co√ªts kilom√©triques r√©els peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en fran√ßais est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les √©coles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59ac6c55-5d83-4988-9be6-50e56fb01c4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59ac6c55-5d83-4988-9be6-50e56fb01c4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59ac6c55-5d83-4988-9be6-50e56fb01c4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id                                           sentence difficulty\n",
              "0   0  Les co√ªts kilom√©triques r√©els peuvent diverger...         C1\n",
              "1   1  Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...         A1\n",
              "2   2  Le test de niveau en fran√ßais est sur le site ...         A1\n",
              "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   4  Dans les √©coles de commerce, dans les couloirs...         B1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpfbtndj0jL"
      },
      "source": [
        "Have a look at the data on which to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7G75Q1gRj49l",
        "outputId": "c382bcc9-1907-4e1e-e23b-821e0cfe0944"
      },
      "source": [
        "df_pred = pd.read_csv('/content/unlabelled_test_data.csv')\n",
        "df_pred.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e0908077-421f-4ac2-9a48-dcc21e795c85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous d√ªmes nous excuser des propos que nous e√ª...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas √©tonnant, car c'est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-m√™me, d'une essence aussi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0908077-421f-4ac2-9a48-dcc21e795c85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0908077-421f-4ac2-9a48-dcc21e795c85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0908077-421f-4ac2-9a48-dcc21e795c85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id                                           sentence\n",
              "0   0  Nous d√ªmes nous excuser des propos que nous e√ª...\n",
              "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2   2  Et, paradoxalement, boire froid n'est pas la b...\n",
              "3   3  Ce n'est pas √©tonnant, car c'est une saison my...\n",
              "4   4  Le corps de Golo lui-m√™me, d'une essence aussi..."
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37hWJ_ckBlk"
      },
      "source": [
        "And this is the format for your submissions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gk9H2dLHkFBa",
        "outputId": "db6c0061-07af-4df5-b45d-24b541f54ec1"
      },
      "source": [
        "df_example_submission = pd.read_csv('/content/sample_submission.csv')\n",
        "df_example_submission.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-068e114e-c57d-4dd4-b747-8923abaaf789\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-068e114e-c57d-4dd4-b747-8923abaaf789')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-068e114e-c57d-4dd4-b747-8923abaaf789 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-068e114e-c57d-4dd4-b747-8923abaaf789');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id difficulty\n",
              "0   0         A1\n",
              "1   1         A1\n",
              "2   2         A1\n",
              "3   3         A1\n",
              "4   4         A1"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfTgL1erjqQ6"
      },
      "source": [
        "### 4. Train your models\n",
        "\n",
        "Set your X and y variables. \n",
        "Set the `random_state=0`\n",
        "Split the data into a train and test set using the following parameters `train_test_split(X, y, test_size=0.2, random_state=0)`.\n",
        "\n",
        "#### 4.1.Baseline\n",
        "What is the baseline for this classification problem? (you can use the highest label frequency from the entire training data, the df above)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4O_pYiHpiRd"
      },
      "source": [
        "np.random.seed = 0\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn. preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDdFr4xsk5Qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26f79fc-28fd-4eb7-d12b-827d675584de"
      },
      "source": [
        "#My baseline\n",
        "df.difficulty.value_counts()\n",
        "\n",
        "round(df.difficulty.value_counts()[0] / len(df), 4)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1694"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlvbPYa0k78l"
      },
      "source": [
        "#### 4.2. Logistic Regression (without data cleaning)\n",
        "\n",
        "Train a simple logistic regression model using a Tfidf vectoriser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEe3-QNlow4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c09f69-6e1e-4884-b320-e6a83483a37c"
      },
      "source": [
        "X = df['sentence']\n",
        "y = df[\"difficulty\"]\n",
        "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "classifier = LogisticRegression(C=2, penalty='l2')\n",
        "\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ-qO8C5oyov"
      },
      "source": [
        "Calculate accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PViIQdnDpASy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3d9f41-e8d3-4cfe-df57-de787ade2c06"
      },
      "source": [
        "# Evaluate the model\n",
        "def evaluate(true, pred):\n",
        "    precision = precision_score(true, pred,average='weighted')\n",
        "    recall = recall_score(true, pred,average='weighted')\n",
        "    f1 = f1_score(true, pred,average='weighted') # on peut remplacer par micro, macro\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")\n",
        "\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[91 35 19 10  4  2]\n",
            " [51 64 32  4  5  8]\n",
            " [12 37 70 14  7 20]\n",
            " [ 6  5 18 68 24 23]\n",
            " [ 3  4 14 41 67 44]\n",
            " [ 7  8  9 15 22 97]]\n",
            "ACCURACY SCORE:\n",
            "0.4760\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4762\n",
            "\tRecall: 0.4760\n",
            "\tF1_Score: 0.4732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3_dp3apcmr"
      },
      "source": [
        "Have a look at the confusion matrix and identify a few examples of sentences that are not well classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSyKq3h_qZmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769f8232-2509-484b-cd5c-a76f82d7d4e9"
      },
      "source": [
        "nwc = []\n",
        "X_test2 = np.array(X_test)\n",
        "y_test2 = np.array(y_test)\n",
        "y_pred2 = np.array(y_pred)\n",
        "for i in range(0, len(y_test2)) : \n",
        "  if y_pred2[i] != y_test2[i] :\n",
        "    nwc.append([i,X_test2[i], y_pred2[i], y_test2[i]])\n",
        "\n",
        "nwc[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  \"C'est en d√©cembre 1967, apr√®s bien des invectives au Parlement, que sa loi relative √† la r√©gulation des naissances, dite loi Neuwirth est vot√©e : elle autorise la vente exclusive des contraceptifs en pharmacie sur ordonnance m√©dicale, avec autorisation parentale pour les mineures\",\n",
              "  'C2',\n",
              "  'C1'],\n",
              " [1,\n",
              "  'Giscard va pourtant r√©ussir √† transformer ce revers en tremplin',\n",
              "  'B2',\n",
              "  'C1'],\n",
              " [2,\n",
              "  \"Un choix difficile mais important : le public fran√ßais √©coute souvent les professionnels de Cannes pour choisir le film qu'il va aller voir au cin√©ma.\",\n",
              "  'B1',\n",
              "  'A2'],\n",
              " [3, \"Le d√©bat porte plut√¥t sur l'utilit√© d'une telle mesure.\", 'C1', 'B1'],\n",
              " [7,\n",
              "  \"Vous eussiez jur√© que les gens la voyaient, l'entendaient rouler pesamment devant eux, retentissante de tous les tr√©sors enferm√©s dans ses flancs.\",\n",
              "  'C2',\n",
              "  'C1']]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TTEiuXasNFg"
      },
      "source": [
        "Generate your first predictions on the `unlabelled_test_data.csv`. make sure your predictions match the format of the `unlabelled_test_data.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXG_yIG_pQ8t"
      },
      "source": [
        "#### 4.3. KNN (without data cleaning)\n",
        "\n",
        "Train a KNN classification model using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPRjD1rSqKKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9296ba23-39be-4126-f12b-e53dac1f1bee"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Define classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "knn_pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', knn_classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "knn_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[121  28   8   1   1   2]\n",
            " [ 98  51  12   1   1   1]\n",
            " [ 81  39  33   3   1   3]\n",
            " [ 49  30  19  29   3  14]\n",
            " [ 48  36  29  15  29  16]\n",
            " [ 37  29  17  23   9  43]]\n",
            "ACCURACY SCORE:\n",
            "0.3187\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4030\n",
            "\tRecall: 0.3187\n",
            "\tF1_Score: 0.3022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6rH2Hx0qtB2"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`n_neighbors`,   `p`, `weights`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRy18Ce_qxPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2216aa90-aa18-4fbf-cfe4-61152ca620f8"
      },
      "source": [
        "knn_classifier_2 = KNeighborsClassifier(n_neighbors =2, weights = 'distance', p=2)\n",
        "\n",
        "knn_pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', knn_classifier_2)])\n",
        "\n",
        "# Fit model on training set\n",
        "knn_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn_pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[113  30  11   2   2   3]\n",
            " [ 76  63  18   4   2   1]\n",
            " [ 59  41  41  14   3   2]\n",
            " [ 30  22  24  41   8  19]\n",
            " [ 33  31  27  26  39  17]\n",
            " [ 34  24  18   8  19  55]]\n",
            "ACCURACY SCORE:\n",
            "0.3667\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4094\n",
            "\tRecall: 0.3667\n",
            "\tF1_Score: 0.3576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFNH1WgNqc62"
      },
      "source": [
        "#### 4.4. Decision Tree Classifier (without data cleaning)\n",
        "\n",
        "Train a Decison Tree classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4PByPdGq0FV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8180a5-9581-48af-c0d2-109d0732c2c7"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "tree_classifier = DecisionTreeClassifier()\n",
        "\n",
        "tree_pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', tree_classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "tree_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = tree_pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[76 40 28  7  6  4]\n",
            " [46 56 33 17  5  7]\n",
            " [30 39 38 23 18 12]\n",
            " [ 8 17 28 45 25 21]\n",
            " [13 20 32 33 42 33]\n",
            " [11 16 26 31 35 39]]\n",
            "ACCURACY SCORE:\n",
            "0.3083\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3108\n",
            "\tRecall: 0.3083\n",
            "\tF1_Score: 0.3066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHjvOp7q11L"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`max_depth`, the depth of the decision tree)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Fzl5BUq8JN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d572c919-c783-4575-82f8-a1225d3c5e18"
      },
      "source": [
        "tree_classifier_2 = DecisionTreeClassifier(max_depth=12)\n",
        "\n",
        "tree_pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', tree_classifier_2)])\n",
        "\n",
        "# Fit model on training set\n",
        "tree_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = tree_pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[97 32  6 18  7  1]\n",
            " [72 40 23 19  7  3]\n",
            " [44 27 29 37 20  3]\n",
            " [15  6 15 69 29 10]\n",
            " [16 11 14 73 40 19]\n",
            " [24  8 16 57 25 28]]\n",
            "ACCURACY SCORE:\n",
            "0.3156\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3290\n",
            "\tRecall: 0.3156\n",
            "\tF1_Score: 0.2991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52Ys3hcq7ku"
      },
      "source": [
        "#### 4.5. Random Forest Classifier (without data cleaning)\n",
        "\n",
        "Try a Random Forest Classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sssF4NIGrNLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7bb249-1da9-4de7-cd0b-ebac8b3afb21"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_classifier = RandomForestClassifier()\n",
        "\n",
        "rfc_pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', rfc_classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "rfc_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rfc_pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[125  17  12   5   1   1]\n",
            " [ 74  57  23   7   2   1]\n",
            " [ 32  37  58  19   8   6]\n",
            " [ 15  14  15  64  19  17]\n",
            " [ 17   8  23  59  43  23]\n",
            " [ 21   8  12  36  25  56]]\n",
            "ACCURACY SCORE:\n",
            "0.4198\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4287\n",
            "\tRecall: 0.4198\n",
            "\tF1_Score: 0.4069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8_3MK1rpZr"
      },
      "source": [
        "#### 4.6. Any other technique, including data cleaning if necessary\n",
        "\n",
        "Try to improve accuracy by training a better model using the techniques seen in class, or combinations of them.\n",
        "\n",
        "As usual, show the accuracy, precision, recall and f1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "\n",
        "# Download the english language model\n",
        "!python -m spacy download fr\n",
        "# Import required packages\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import string\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from spacy.lang.fr import French"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ9mU0aV5fqw",
        "outputId": "1cc199d6-960a-4b0e-c7d4-18237ff65e29"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.13)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "\u001b[38;5;3m‚ö† As of spaCy v3.0, shortcuts like 'fr' are deprecated. Please use the\n",
            "full pipeline package name 'fr_core_news_sm' instead.\u001b[0m\n",
            "Collecting fr-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.2.0/fr_core_news_sm-3.2.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.4 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.1)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spacy.load('fr_core_news_sm')"
      ],
      "metadata": {
        "id": "04JJgQLW51Hq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "\n",
        "    punctuations = string.punctuation\n",
        "    stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
        "\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = sp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # Remove anonymous dates and people\n",
        "    mytokens = [ word.replace('xx/', '').replace('xxxx/', '').replace('xx', '') for word in mytokens ]\n",
        "    mytokens = [ word for word in mytokens if word not in [\"xxxx\", \"xx\", \"\"] ]\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "metadata": {
        "id": "4AwHwYiy6s7G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX5AjvvKr_nW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74db87c1-4214-492d-a96f-0b9f90fe2461"
      },
      "source": [
        "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "tfidf3 = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', ngram_range=(1, 8), tokenizer=spacy_tokenizer,analyzer=\"char\")\n",
        "\n",
        "    # Define classifier\n",
        "classifier = LogisticRegression(solver ='lbfgs', penalty='l2', C=5)\n",
        "\n",
        "    # Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf3),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "    # Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[100  34  21   3   3   0]\n",
            " [ 47  73  34   6   2   2]\n",
            " [ 12  25  87  21   8   7]\n",
            " [  0   8   7  68  28  33]\n",
            " [  3   2   8  33  76  51]\n",
            " [  1   5   8  19  24 101]]\n",
            "ACCURACY SCORE:\n",
            "0.5260\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.5264\n",
            "\tRecall: 0.5260\n",
            "\tF1_Score: 0.5240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Best estimation ! -> Download Data\n",
        "\n",
        "df_pred = pd.read_csv('/content/unlabelled_test_data.csv')\n",
        "x = df_pred[\"sentence\"]\n",
        "y_predictions = pipe.predict(x)\n",
        "\n",
        "\n",
        "predi = df_pred\n",
        "predi[\"difficulty\"] = y_predictions\n",
        "predicsv = predi[['id','difficulty']]\n",
        "\n",
        "from google.colab import files\n",
        "predicsv.to_csv('predicsv.csv') \n",
        "files.download('predicsv.csv')"
      ],
      "metadata": {
        "id": "zCiAPhNnFNoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples of other tentatives to do better :\n",
        "\n",
        "Include Gridsearch, standardization, alternative data cleaning and PCA."
      ],
      "metadata": {
        "id": "fi8DlMkxZvBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "tfidf4 = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', ngram_range=(1, 8) , tokenizer=spacy_tokenizer,analyzer=\"char\")\n",
        "\n",
        "#tfidf2 = TfidfVectorizer(ngram_range=(1,8), analyzer=\"char\")\n",
        "#tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1,8), analyzer=\"char\")\n",
        "\n",
        "    # Define classifier\n",
        "classifier = LogisticRegressionCV (Cs =10, cv = 3, solver ='lbfgs', penalty='l2',class_weight = 'balanced')\n",
        "\n",
        "    # Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf4),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "\n",
        "\n",
        "    # Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "evaluate(y_test, y_pred)\n",
        "print(\"-----------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWFQINsIGXIT",
        "outputId": "24de82c6-32dd-4fab-ea7f-2fd86ec26723"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[100  35  19   3   2   2]\n",
            " [ 45  71  38   6   2   2]\n",
            " [ 12  24  87  20  10   7]\n",
            " [  1   7  11  66  28  31]\n",
            " [  3   2  11  33  77  47]\n",
            " [  1   3   9  20  28  97]]\n",
            "ACCURACY SCORE:\n",
            "0.5188\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.5189\n",
            "\tRecall: 0.5188\n",
            "\tF1_Score: 0.5170\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "           ('vect', TfidfVectorizer()),\n",
        "           ('clf', LogisticRegression())])\n",
        "parameters = {\n",
        "'vect__max_df': (0.75, 1.0),\n",
        "# 'vect__max_features': (None, 5000, 10000, 50000),\n",
        "'vect__ngram_range': ((1, 2), (1,3),(1,8),(3,7)),  \n",
        "# 'tfidf__use_idf': (True, False),\n",
        "'vect__norm': ('l1', 'l2', None),\n",
        "'clf__solver': ('lbfgs','newton-cg'),\n",
        " 'clf__C': (10, 100),\n",
        " #'clf__class_weight': ('balanced'),\n",
        " 'clf__max_iter': (100, 500)\n",
        "}\n",
        "\n",
        "grid= GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5,scoring='accuracy')\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "grid.best_params_\n",
        "\n",
        "# find best model score\n",
        "grid.score(X_train, y_train)\n",
        "\n",
        "print(\"Total score for %s  is %s  \", grid.best_params_, grid.score(X_train, y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "V5y3ke_GZrpa",
        "outputId": "d28b293e-afaf-4a21-9b9d-d3348937e683"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-636dd5e26990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "           ('vect', TfidfVectorizer(tokenizer = spacy_tokenizer, analyzer = \"char\")),\n",
        "           ('clf', LogisticRegression(max_iter = 100))])\n",
        "\n",
        "parameters = {\n",
        "    # 'vect__max_df': 1.0,\n",
        "#'vect__tokenizer': (spacy_tokenizer),\n",
        "# 'vect__max_features': (None, 5000, 10000, 50000),\n",
        "'vect__ngram_range': ((1,8),(3,7)),  \n",
        "# 'tfidf__use_idf': (True, False),\n",
        "'vect__norm': ('l1','l2'),\n",
        "'clf__solver': ('lbfgs','newton-cg'),\n",
        " 'clf__C': (10, 100),\n",
        " #'clf__class_weight': ('balanced'),\n",
        " #'clf__max_iter': (50,100)\n",
        "}\n",
        "\n",
        "grid= GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=2, cv=cv,scoring='accuracy')\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "grid.best_params_\n",
        "\n",
        "# find best model score\n",
        "grid.score(X_train, y_train)\n",
        "\n",
        "print(\"Total score for %s  is %s  \", grid.best_params_, grid.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "mi72iB1ErqlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred =grid.predict(X_test)\n",
        "evaluate(y_test, y_pred)"
      ],
      "metadata": {
        "id": "XeQkeY9oeJE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "# Define cleaning function\n",
        "def data_cleaner(sms):\n",
        "\n",
        "    # Define stopwords\n",
        "    stop_words = stopwords.words('french') #important !\n",
        "\n",
        "    # Define tokenizer and stemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.stem import PorterStemmer\n",
        "    \n",
        "    # Remove digits\n",
        "    sms = re.sub(r\"\\d+\",\"\", sms)\n",
        "    \n",
        "    # Lowercase\n",
        "    sms = sms.lower()\n",
        "    \n",
        "    # Remove punctuation\n",
        "    sms = re.sub(r\"[^\\w\\s\\d]\",\"\", sms)\n",
        "    \n",
        "    # Remove stop words\n",
        "    sms = sms.split()\n",
        "    sms = \" \".join([word for word in sms if not word in stop_words])\n",
        "    \n",
        "    # Tokenize\n",
        "    sms = word_tokenize(sms)\n",
        "    \n",
        "    # Stemming\n",
        "    ps = PorterStemmer()\n",
        "    sms = [ps.stem(word) for word in sms]\n",
        "    \n",
        "    return sms\n",
        "\n"
      ],
      "metadata": {
        "id": "aMtMW8hS7anf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Clean X_train as example\n",
        "X_train.apply(data_cleaner)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Define vectorizer - use above cleaning function\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, tokenizer=data_cleaner, ngram_range=(1,5), min_df=1, max_df=1.0, analyzer =\"char\")\n",
        "\n",
        "# Fit and transform X_train and X_test\n",
        "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "\n",
        "X_train_vec = tfidf.fit_transform(X_train).toarray()\n",
        "X_test_vec = tfidf.transform(X_test).toarray()\n",
        "print(X_train_vec.shape)\n",
        "X_train_vec\n",
        "\n",
        "# Define PCA\n",
        "pca = PCA(n_components=10)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n",
        "\n",
        "# Define Model\n",
        "pipe = Pipeline([\n",
        "                 ('logistic reg', LogisticRegression(C=5, solver ='lbfgs', penalty='l2',class_weight = 'balanced'))\n",
        "                 ])\n",
        "# Fit model\n",
        "start = time.time()\n",
        "pipe.fit(X_train_vec, y_train)\n",
        "end = time.time()\n",
        "print('Time: ', round(end-start, 4))\n",
        "print('Train Accuracy: ', round(pipe.score(X_train_vec, y_train), 4))\n",
        "print('Test Accuracy: ', round(pipe.score(X_test_vec, y_test), 4))\n",
        "\n",
        "    # Predictions\n",
        "y_pred = pipe.predict(X_test_vec)\n"
      ],
      "metadata": {
        "id": "bV_8uofhbALO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knn With PCA and standardization and grid search\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Define Model\n",
        "pipe = Pipeline([\n",
        "                 ('scaler', StandardScaler()),\n",
        "                 ('pca', pca),\n",
        "                 ('knn', KNeighborsClassifier(weights = 'distance')),\n",
        "                 ])\n",
        "# Fit model\n",
        "\n",
        "parameters = {\n",
        "    # 'vect__max_df': 1.0,,\n",
        "# 'vect__max_features': (None, 5000, 10000, 50000),\n",
        "'knn__n_neighbors': ((1,2,5,10,15,20,50,100,200))}\n",
        "\n",
        "\n",
        "grid= GridSearchCV(pipe, parameters, n_jobs=-1, verbose=2, cv=cv,scoring='accuracy')\n",
        "\n",
        "grid.fit(X_train_vec, y_train)\n",
        "\n",
        "grid.best_params_\n",
        "\n",
        "# find best model score\n",
        "grid.score(X_train, y_train)\n",
        "\n",
        "print(\"Total score for %s  is %s  \", grid.best_params_, grid.score(X_train, y_train))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZTWws9qr8drf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rmmafkWRexAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bays methods"
      ],
      "metadata": {
        "id": "FN5ZxGvBexQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Naive Bays\n",
        "X = df['sentence']\n",
        "y = df[\"difficulty\"]\n",
        "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "nb = Pipeline([('vect', TfidfVectorizer(analyzer='word', min_df=1, ngram_range=(1,3))), #tokenizer=spacy_tokenizer, min_df=1, max_df=0.7, analyzer='char'                  \n",
        "               ('clf', MultinomialNB(alpha=0.05))])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))"
      ],
      "metadata": {
        "id": "0XW1852X_no7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method of a re-sampling and a config test :"
      ],
      "metadata": {
        "id": "bHDfd_wve3RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of methods to obtain the best possible accuracy\n",
        "#X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "df_new = pd.concat([df[df[\"difficulty\"] == \"A1\"].sample(790), df[df[\"difficulty\"] == \"A2\"].sample(790),df[df[\"difficulty\"] == \"B1\"].sample(790),df[df[\"difficulty\"] == \"B2\"].sample(790),\n",
        "df[df[\"difficulty\"] == \"C1\"].sample(790),df[df[\"difficulty\"] == \"C2\"].sample(790)], axis=0).reset_index()\n",
        "# Select features\n",
        "X = df_new['sentence'] # the features we want to analyze\n",
        "ylabels = df_new['difficulty'] # the labels, or answers, we want to test against\n",
        "\n",
        "# Train test split\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X, ylabels, test_size=0.2, random_state=1234, stratify=ylabels)\n",
        "\n",
        "\n",
        "\n",
        "#1) Improve text preparation\n",
        "def configs():\n",
        "\n",
        "    models = list()\n",
        "    \n",
        "    # Define config lists\n",
        "    ngram_range = [(1,4), (1,5), (1, 6), (2, 4), (2, 5), (3, 6)]\n",
        "    min_df = [1]\n",
        "    max_df = [1.0]\n",
        "    analyzer=['char'] #'word'\n",
        "    \n",
        "    # Create config instances\n",
        "    for n in ngram_range:\n",
        "        for i in min_df:\n",
        "            for j in max_df:\n",
        "              for a in analyzer:\n",
        "                    cfg = [n, i, j, a]\n",
        "                    models.append(cfg)\n",
        "    return models\n",
        "\n",
        "configs = configs()\n",
        "configs[:10]\n",
        "\n",
        "\n",
        "# Define list for result\n",
        "result = []\n",
        "\n",
        "for config in configs:\n",
        "\n",
        "    # Redefine vectorizer\n",
        "    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer, \n",
        "                                   ngram_range=config[0],\n",
        "                                   min_df=config[1], max_df=config[2], analyzer=config[3])\n",
        "\n",
        "    # Define classifier\n",
        "    classifier = LogisticRegression()\n",
        "\n",
        "    # Create pipeline\n",
        "    pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "    # Fit model on training set\n",
        "    pipe.fit(X_train_b, y_train_b)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipe.predict(X_test_b)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "    print(\"CONFIG: \", config)\n",
        "    evaluate(y_test_b, y_pred)\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # Append to result\n",
        "    result.append([config, accuracy_score(y_test_b, y_pred)])"
      ],
      "metadata": {
        "id": "QvX-Dbsee9zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82FvnJycsBFf"
      },
      "source": [
        "#### 4.7. Show a summary of your results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result for algorithms whithout data cleaning"
      ],
      "metadata": {
        "id": "Wbg3e_dYfCu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"Logistic regression\":[0.4762,0.4760,0.4732,0.4760],\n",
        "                 \"kNN\":[0.4094,0.3667,0.3576,0.3667],\"Decision Tree\":[0.3098,0.3083,0.3054,0.3083],\"Random Forest\" : [0.4211,0.4156,0.4026,0.4156],\n",
        "                 \"Final method\" : [0.5264,0.5260,0.5240,0.5260]})\n",
        "df.index = ['Precision', 'Recall','F1 score', 'Accuracy']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "wm7rbQ0WtOuP",
        "outputId": "d04d8673-d18d-4bc7-b00b-2df93227255c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8d2ff22a-ba35-4584-9dce-048329e5b403\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic regression</th>\n",
              "      <th>kNN</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Final method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.4762</td>\n",
              "      <td>0.4094</td>\n",
              "      <td>0.3098</td>\n",
              "      <td>0.4211</td>\n",
              "      <td>0.5264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.4760</td>\n",
              "      <td>0.3667</td>\n",
              "      <td>0.3083</td>\n",
              "      <td>0.4156</td>\n",
              "      <td>0.5260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1 score</th>\n",
              "      <td>0.4732</td>\n",
              "      <td>0.3576</td>\n",
              "      <td>0.3054</td>\n",
              "      <td>0.4026</td>\n",
              "      <td>0.5240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.4760</td>\n",
              "      <td>0.3667</td>\n",
              "      <td>0.3083</td>\n",
              "      <td>0.4156</td>\n",
              "      <td>0.5260</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d2ff22a-ba35-4584-9dce-048329e5b403')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d2ff22a-ba35-4584-9dce-048329e5b403 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d2ff22a-ba35-4584-9dce-048329e5b403');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Logistic regression     kNN  ...  Random Forest  Final method\n",
              "Precision               0.4762  0.4094  ...         0.4211        0.5264\n",
              "Recall                  0.4760  0.3667  ...         0.4156        0.5260\n",
              "F1 score                0.4732  0.3576  ...         0.4026        0.5240\n",
              "Accuracy                0.4760  0.3667  ...         0.4156        0.5260\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Conclusion**\n",
        "\n",
        "To conclude, Logisitc Regression was found to be the most efficient tools for this project. It was the classifier with the best performance among those tested without data cleaning. We can note that Naive Bays algorithms gives also a good accuracy.\n",
        "\n",
        "The configs tests showed us that the n_gram range was what impacted the most the accuracy of the logistic regression, and show best performances for (1,8). The disadvantage of this method could be the calcul time which can be long.\n",
        "\n",
        "The PCA method used to diminish the computing time impacted in a bad way too much the performance to keep it. \n",
        "\n",
        "The GridsearchCV function helped to determine the best hyperparameters in a faster way than the config tests and helped to improve a bit our final accuracy."
      ],
      "metadata": {
        "id": "LXExA3UYVvAm"
      }
    }
  ]
}